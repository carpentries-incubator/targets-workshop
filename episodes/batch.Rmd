---
title: 'Batch and Parallel Processing'
teaching: 10
exercises: 2
---

:::::::::::::::::::::::::::::::::::::: questions 

- How can we specify many targets without typing everything out?
- How can we build targets in parallel?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Be able to specify targets using branching
- Be able to build targets in parallel

::::::::::::::::::::::::::::::::::::::::::::::::

```{r}
#| label: setup
#| echo: FALSE
#| message: FALSE
#| warning: FALSE
library(targets)
library(tarchetypes)
source("https://raw.githubusercontent.com/joelnitta/targets-workshop/main/episodes/files/functions.R") # nolint
```

## Why batch and parallel processing?

One of the major strengths of `targets` is the ability to define many targets from a single line of code (batch processing).
This not only saves you typing, it also **reduces the risk of errors** since there is less chance of making a typo.
Furthermore, it is related to another powerful feature: `targets` can run multiple analyses in parallel (at the same time), thereby **making your analysis finish sooner**.

## Types of branching

Batching in `targets` is called "branching."
There are two types of branching, **dynamic branching** and **static branching**.
"Branching" refers to the idea that you can provide a single specification for how to make targets (the "pattern"), and `targets` generates multiple targets from it ("branches").
"Dynamic" means that the branches that result from the pattern do not have to be defined ahead of time---they are a dynamic result of the code.

In this workshop, we will only cover dynamic branching since it is generally easier to write (static branching requires use of [meta-programming](https://books.ropensci.org/targets/static.html#metaprogramming), an advanced topic). For more information about each and when you might want to use one or the other (or some combination of the two), [see the `targets` package manual](https://books.ropensci.org/targets/dynamic.html).

## Example without branching

To see how this works, let's use an example based on the `palmerpenguins` dataset.
Our hypothesis is that bill depth decreases with bill length.
We want to test this using several alternative models.
The models will either ignore species identity, add a parameter for species, or add an interaction effect between species and bill length.

This is what a workflow for such an analysis might look like **without branching**:

```{r}
#| label: example-model-show-1
#| eval: FALSE
library(targets)
library(tarchetypes)
library(palmerpenguins)
library(broom)

tar_plan(
  # Load data from package
  penguin_data = palmerpenguins::penguins,
  # Build models
  combined_model = lm(
    bill_depth_mm ~ bill_length_mm, data = penguin_data),
  species_model = lm(
    bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
  interaction_model = lm(
    bill_depth_mm ~ bill_length_mm * species, data = penguin_data),
  # Get model summaries
  combined_summary = glance(combined_model),
  species_summary = glance(species_model),
  interaction_summary = glance(interaction_model)
)
```

```{r}
#| label: example-model-hide-1
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  writeLines("Hello World", "_targets/user/data/hello.txt")
  tar_script({
     library(targets)
     library(tarchetypes)
     library(palmerpenguins)
     library(broom)

     tar_plan(
       # Load data from package
       penguin_data = palmerpenguins::penguins,
       # Build models
       combined_model = lm(
         bill_depth_mm ~ bill_length_mm, data = penguin_data),
       species_model = lm(
         bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
       interaction_model = lm(
         bill_depth_mm ~ bill_length_mm * species, data = penguin_data),
       # Get model summaries
       combined_summary = glance(combined_model),
       species_summary = glance(species_model),
       interaction_summary = glance(interaction_model)
     )
  })
  tar_make()
})
```

It worked. Let's check some of the model output:

```{r}
#| label: example-model-show-2
#| eval: FALSE
tar_read(combined_summary)
```

```{r}
#| label: example-model-hide-2
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  writeLines("Hello World", "_targets/user/data/hello.txt")
  tar_script({
     library(targets)
     library(tarchetypes)
     library(palmerpenguins)
     library(broom)

     tar_plan(
       # Load data from package
       penguin_data = palmerpenguins::penguins,
       # Build models
       combined_model = lm(
         bill_depth_mm ~ bill_length_mm, data = penguin_data),
       species_model = lm(
         bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
       interaction_model = lm(
         bill_depth_mm ~ bill_length_mm * species, data = penguin_data),
       # Get model summaries
       combined_summary = glance(combined_model),
       species_summary = glance(species_model),
       interaction_summary = glance(interaction_model)
     )
  })
  tar_make(reporter = "silent")
  tar_read(combined_summary)
})
```

This way of writing the pipeline is repetitive: we have to call `glance()` each time we want to obtain summary statistics for each model.
Furthermore, each summary target (`combined_summary`, etc.) is explicitly named and typed out manually.
It would be fairly easy to make a typo and end up with the wrong model being summarized.

## Example with branching

### First attempt

Let's see how to write the same plan using **dynamic branching**:

```{r}
#| label: example-model-show-3
#| eval: FALSE
library(targets)
library(tarchetypes)
library(palmerpenguins)
library(broom)

tar_plan(
  # Load data from package
  penguin_data = palmerpenguins::penguins,
  # Build models
  models = list(
    combined_model = lm(
      bill_depth_mm ~ bill_length_mm, data = penguin_data),
    species_model = lm(
      bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
    interaction_model = lm(
      bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
  ),
  # Get model summaries
  tar_target(
    model_summaries,
    glance(models[[1]]),
    pattern = map(models)
  )
)
```

```{r}
#| label: example-model-hide-3
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  writeLines("Hello World", "_targets/user/data/hello.txt")
  tar_script({
    library(targets)
    library(tarchetypes)
    library(palmerpenguins)
    library(broom)
    tar_plan(
      # Load data from package
      penguin_data = palmerpenguins::penguins,
      # Build models
      models = list(
        combined_model = lm(
          bill_depth_mm ~ bill_length_mm, data = penguin_data),
        species_model = lm(
          bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
        interaction_model = lm(
          bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
      ),
      # Get model summaries
      tar_target(
        model_summaries,
        glance(models[[1]]),
        pattern = map(models)
      )
    )
  })
  tar_make()
})
```

What is going on here?

First, let's look at the output of `tar_make()`.

There is a series of smaller targets (branches) that are each named like `model_summaries_f9795da2`, then one overall `model_summaries` target.
That is the result of specifying targets using branching: each of the smaller targets are the "branches" that comprise the overall target.
Since `targets` has no way of knowing ahead of time how many branches there will be or what they represent, it names each one using this series of numbers and letters (the "hash").
`targets` builds each branch one at a time, then combines them into the overall target.

Next, let's look in more detail about how the workflow is set up.

Unlike the non-branching version, we defined the models in a list (instead of one target per model).
This is because dynamic branching is similar to the `apply()` or `purrrr::map()` method of looping: it applies a function to each element of a list.
So we need to prepare the input for looping as a list.

Take a look at the command to build the target `model_summaries`.
As before, the first argument is the name of the target to build, and the second is the command to build it.
Here, we apply the `glance()` function to each element of `models` (the `[[1]]` is necessary because when the function gets applied, each element is actually a nested list, and we need to remove one layer of nesting).
Finally, there is an argument we haven't seen before, `pattern`, which indicates that this target should be built using dynamic branching.
`map` means to apply the command to each element of the input list (`models`) sequentially.

Now that we understand how the branching workflow is constructed, let's inspect the output:

```{r}
#| label: example-model-show-4
#| eval: FALSE
tar_read(model_summaries)
```

```{r}
#| label: example-model-hide-4
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  writeLines("Hello World", "_targets/user/data/hello.txt")
  tar_script({
    library(targets)
    library(tarchetypes)
    library(palmerpenguins)
    library(broom)
    tar_plan(
      # Load data from package
      penguin_data = palmerpenguins::penguins,
      # Build models
      models = list(
        combined_model = lm(
          bill_depth_mm ~ bill_length_mm, data = penguin_data),
        species_model = lm(
          bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
        interaction_model = lm(
          bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
      ),
      # Get model summaries
      tar_target(
        model_summaries,
        glance(models[[1]]),
        pattern = map(models)
      )
    )
  })
  tar_make(reporter = "silent")
  tar_read(model_summaries)
})
```

The model summary statistics are all included in a single dataframe, which is convenient.

But there's one problem: **we can't tell which row came from which model!** It would be unwise to assume that they are in the same order as the list of models.

This is due to the way dynamic branching works: by default, there is no information about the provenance of each target preserved in the output.

How can we fix this?

### Second attempt

The key to obtaining useful output from branching pipelines is to include the necessary information in the output of each individual branch.
Here, we want to know the kind of model that corresponds to each row of the model summaries.
To do that, we need to write a **custom function**.
You will need to write custom functions frequently when using `targets`, so it's good to get used to it!

Here is the function. Save this in `R/functions.R`:

```{r}
#| label: example-model-show-5
#| eval: FALSE
glance_with_mod_name <- function(model_in_list) {
  model_name <- names(model_in_list)
  model <- model_in_list[[1]]
  broom::glance(model) %>%
    mutate(model_name = model_name)
}
```

Our new pipeline looks almost the same as before, but this time we use the custom function instead of `broom::glance()`.

```{r}
#| label: example-model-show-6
#| eval: FALSE
library(targets)
library(tarchetypes)
library(palmerpenguins)
library(tidyverse)

tar_plan(
  # Load data from package
  penguin_data = palmerpenguins::penguins,
  # Build models
  models = list(
    combined_model = lm(
      bill_depth_mm ~ bill_length_mm, data = penguin_data),
    species_model = lm(
      bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
    interaction_model = lm(
      bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
  ),
  # Get model summaries
  tar_target(
    model_summaries,
    glance_with_mod_name(models),
    pattern = map(models)
  )
)
```

```{r}
#| label: example-model-hide-6
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  tar_script({
    library(targets)
    library(tarchetypes)
    library(palmerpenguins)
    library(tidyverse)
    glance_with_mod_name <- function(model_in_list) {
      model_name <- names(model_in_list)
      model <- model_in_list[[1]]
      broom::glance(model) %>%
        mutate(model_name = model_name)
    }
    tar_plan(
      # Load data from package
      penguin_data = palmerpenguins::penguins,
      # Build models
      models = list(
        combined_model = lm(
          bill_depth_mm ~ bill_length_mm, data = penguin_data),
        species_model = lm(
          bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
        interaction_model = lm(
          bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
      ),
      # Get model summaries
      tar_target(
        model_summaries,
        glance_with_mod_name(models),
        pattern = map(models)
      )
    )
  })
  tar_make()
})
```

And this time, when we load the `model_summaries`, we can tell which model corresponds to which row.

```{r}
#| label: example-model-hide-7
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  tar_script({
    library(targets)
    library(tarchetypes)
    library(palmerpenguins)
    library(tidyverse)
    glance_with_mod_name <- function(model_in_list) {
      model_name <- names(model_in_list)
      model <- model_in_list[[1]]
      broom::glance(model) %>%
        mutate(model_name = model_name)
    }
    tar_plan(
      # Load data from package
      penguin_data = palmerpenguins::penguins,
      # Build models
      models = list(
        combined_model = lm(
          bill_depth_mm ~ bill_length_mm, data = penguin_data),
        species_model = lm(
          bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
        interaction_model = lm(
          bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
      ),
      # Get model summaries
      tar_target(
        model_summaries,
        glance_with_mod_name(models),
        pattern = map(models)
      )
    )
  })
  tar_make(reporter = "silent")
  tar_read(model_summaries)
})
```

::::::::::::::::::::::::::::::::::::: {.challenge}

## Challenge: What other kinds of patterns are there?

So far, we have only used a single function in conjunction with the `pattern` argument, `map()`, which applies the function to each element of its input in sequence.

Can you think of any other ways you might want to apply a branching pattern?

:::::::::::::::::::::::::::::::::: {.solution}

Some other ways of applying branching patterns include:

- crossing: one branch per combination of elements (`cross()` function)
- slicing: one branch for each of a manually selected set of elements (`slice()` function)
- sampling: one branch for each of a randomly selected set of elements (`sample()` function)

You can [find out more about different branching patterns in the `targets` manual](https://books.ropensci.org/targets/dynamic.html#patterns).

::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::

## Parallel processing

Once a pipeline starts to include many targets, you may want to think about parallel processing.
This takes advantage of multiple processors in your computer to build multiple targets at the same time.

::::::::::::::::::::::::::::::::::::: {.callout}

Parallel computing should only be used if your workflow has a structure such that it makes sense---if your workflow only consists of a linear sequence of targets, then there is nothing to parallelize.

:::::::::::::::::::::::::::::::::::::

`targets` includes support for high-performance computing, cloud computing, and various parallel backends.
Here, we assume you are running this analysis on a laptop and so will use a relatively simple backend.
If you are interested in high-performance computing, [see the `targets` manual](https://books.ropensci.org/targets/hpc.html).

### Install R packages for parallel computing

For this demo, we will use the [`future` backend](https://github.com/HenrikBengtsson/future).

You will need to install several packages:

```{r}
#| label: install-future
#| eval: false
install.packages("future")
install.packages("future.batchtools")
install.packages("future.callr")
```

### Set up workflow

There are a few things you need to change to enable parallel processing with `future`:

- Load the `future` and `future.callr` packages
- Add a line with `plan(callr)`
- When you run the pipeline, use `tar_make_future(workers = 2)` instead of `tar_make()`

Here, `workers = 2` is the number of processes to run in parallel. You may increase this up to the number of cores available on your machine.

To show how this works we will simulate a long(ish) running analysis with the `Sys.sleep()` function, which just tells the computer to wait some number of seconds.

```{r}
#| label: example-model-show-8
#| eval: FALSE
library(targets)
library(tarchetypes)
library(future)
library(future.callr)

plan(callr)

long_square <- function(data) {
  Sys.sleep(3)
  data^2
}

tar_plan(
  some_data = c(1, 2, 3, 4),
  tar_target(
    data_squared,
    long_square(some_data),
    pattern = map(some_data)
  )
)
```

Here is the output when running with `tar_make_future(workers = 2)`:

```{r}
#| label: example-model-hide-8
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  tar_script({
    library(targets)
    library(tarchetypes)
    library(future)
    library(future.callr)
    plan(callr)
    long_square <- function(data) {
      Sys.sleep(3)
      data^2
    }
    tar_plan(
      some_data = c(1, 2, 3, 4),
      tar_target(
        data_squared,
        long_square(some_data),
        pattern = map(some_data)
      )
    )
  })
  tar_make_future(workers = 2)
})
```

Notice that although the time required to build each individual target is about 3 seconds, the total time to run the entire workflow is less than the sum of the individual target times! That is proof that processes are running in parallel **and saving you time**.

The unique and powerful thing about targets is that **we did not need to change our custom function to run it in parallel**. We only adjusted *the workflow*. This means it is relatively easy to refactor (modify) a workflow for running sequentially locally or running in parallel in a high-performance context.

We can see this by applying parallel processing to a workflow that we were previously running sequentially, the penguins analysis:

```{r}
#| label: example-model-show-9
#| eval: FALSE
library(targets)
library(tarchetypes)
library(palmerpenguins)
library(tidyverse)
library(future)
library(future.callr)

plan(callr)

tar_plan(
  # Load data from package
  penguin_data = palmerpenguins::penguins,
  # Build models
  models = list(
    combined_model = lm(
      bill_depth_mm ~ bill_length_mm, data = penguin_data),
    species_model = lm(
      bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
    interaction_model = lm(
      bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
  ),
  # Get model summaries
  tar_target(
    model_summaries,
    glance_with_mod_name(models),
    pattern = map(models)
  )
)
```

```{r}
#| label: example-model-hide-9
#| echo: FALSE
tar_dir({
  fs::dir_create("_targets/user/data")
  tar_script({
    library(targets)
    library(tarchetypes)
    library(palmerpenguins)
    library(tidyverse)
    library(future)
    library(future.callr)
    plan(callr)
    glance_with_mod_name <- function(model_in_list) {
      model_name <- names(model_in_list)
      model <- model_in_list[[1]]
      broom::glance(model) %>%
        mutate(model_name = model_name)
    }
    tar_plan(
      # Load data from package
      penguin_data = palmerpenguins::penguins,
      # Build models
      models = list(
        combined_model = lm(
          bill_depth_mm ~ bill_length_mm, data = penguin_data),
        species_model = lm(
          bill_depth_mm ~ bill_length_mm + species, data = penguin_data),
        interaction_model = lm(
          bill_depth_mm ~ bill_length_mm * species, data = penguin_data)
      ),
      # Get model summaries
      tar_target(
        model_summaries,
        glance_with_mod_name(models),
        pattern = map(models)
      )
    )
  })
  tar_make_future(workers = 2)
})
```

You won't notice much difference since these computations run so quickly, but this demonstrates how easy it is to make massive gains in efficiency with your own real analysis by using parallel computing.

::::::::::::::::::::::::::::::::::::: keypoints 

- Dynamic branching is easier to use, but the names of the targets it creates are arbitrary
- Parallel computing works at the level of the workflow, not the function

::::::::::::::::::::::::::::::::::::::::::::::::
